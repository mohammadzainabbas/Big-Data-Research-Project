{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "from typing import List, Tuple, Dict, Any, Union\n",
    "import networkx as nx\n",
    "from dataclasses import dataclass, field\n",
    "from scipy.spatial import distance\n",
    "from stg_utils import *\n",
    "from sys import path\n",
    "path.append(\"/Users/mohammadzainabbas/Masters/CS/Big-Data-Research-Project/src/object_detection/yolov7_with_object_tracking\")\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, \\\n",
    "                check_imshow, non_max_suppression, apply_classifier, \\\n",
    "                scale_coords, xyxy2xywh, strip_optimizer, set_logging, \\\n",
    "                increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "from sort import *\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [       1647,         121,        1716,         284,     0.91595,           0],\n",
    "    [       1606,         609,        1716,         863,     0.90923,           0],\n",
    "    [        249,         787,         374,        1080,     0.89867,           0],\n",
    "    [        801,         245,         857,         422,     0.88594,           0],\n",
    "    [       1452,          35,        1535,         185,     0.88343,           0],\n",
    "    [       1575,         913,        1715,        1079,     0.87925,           0],\n",
    "    [        713,         229,         783,         409,     0.87111,           0],\n",
    "    [        871,         391,         985,         613,     0.86602,           0],\n",
    "    [       1347,          70,        1395,         151,     0.81387,           1],\n",
    "    [        879,          77,         943,         232,     0.80651,           0],\n",
    "    [       1797,         180,        1864,         367,     0.78584,           0],\n",
    "    [        886,         482,        1022,         643,     0.78523,           1],\n",
    "    [        294,         298,         364,         481,     0.71708,           0],\n",
    "    [        615,          78,         690,         193,     0.71245,          58],\n",
    "    [        616,        1007,         752,        1080,     0.69813,           0],\n",
    "    [       1509,          90,        1553,         192,     0.69539,           1],\n",
    "    [       1646,         686,        1712,         791,     0.69249,          26],\n",
    "    [       1347,          16,        1402,         129,     0.68978,           0],\n",
    "    [       1154,           0,        1197,          75,     0.65086,           0],\n",
    "    [         11,         277,          90,         435,     0.58677,           0],\n",
    "    [        985,           0,        1032,         127,      0.5406,           0],\n",
    "    [       1324,           0,        1358,          47,     0.53892,           0],\n",
    "    [        247,         951,         284,        1023,     0.34445,          26],\n",
    "    [        284,         398,         315,         456,     0.30317,          26],\n",
    "    [        593,         244,         802,         417,     0.29631,          13],\n",
    "    [       1837,         262,        1883,         344,     0.28662,           0],\n",
    "    [       1806,         208,        1857,         292,     0.26673,          24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1647, 121, 1716, 284, 0.91595, 0],\n",
       " [1606, 609, 1716, 863, 0.90923, 0],\n",
       " [249, 787, 374, 1080, 0.89867, 0],\n",
       " [801, 245, 857, 422, 0.88594, 0],\n",
       " [1452, 35, 1535, 185, 0.88343, 0],\n",
       " [1575, 913, 1715, 1079, 0.87925, 0],\n",
       " [713, 229, 783, 409, 0.87111, 0],\n",
       " [871, 391, 985, 613, 0.86602, 0],\n",
       " [1347, 70, 1395, 151, 0.81387, 1],\n",
       " [879, 77, 943, 232, 0.80651, 0],\n",
       " [1797, 180, 1864, 367, 0.78584, 0],\n",
       " [886, 482, 1022, 643, 0.78523, 1],\n",
       " [294, 298, 364, 481, 0.71708, 0],\n",
       " [615, 78, 690, 193, 0.71245, 58],\n",
       " [616, 1007, 752, 1080, 0.69813, 0],\n",
       " [1509, 90, 1553, 192, 0.69539, 1],\n",
       " [1646, 686, 1712, 791, 0.69249, 26],\n",
       " [1347, 16, 1402, 129, 0.68978, 0],\n",
       " [1154, 0, 1197, 75, 0.65086, 0],\n",
       " [11, 277, 90, 435, 0.58677, 0],\n",
       " [985, 0, 1032, 127, 0.5406, 0],\n",
       " [1324, 0, 1358, 47, 0.53892, 0],\n",
       " [247, 951, 284, 1023, 0.34445, 26],\n",
       " [284, 398, 315, 456, 0.30317, 26],\n",
       " [593, 244, 802, 417, 0.29631, 13],\n",
       " [1837, 262, 1883, 344, 0.28662, 0],\n",
       " [1806, 208, 1857, 292, 0.26673, 24]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Node:\n",
    "    id: int = field(default=0)\n",
    "    x1: int = field(default=0)\n",
    "    y1: int = field(default=0)\n",
    "    x2: int = field(default=0)\n",
    "    y2: int = field(default=0)\n",
    "    conf: float = field(default=float(0))\n",
    "    detclass: int = field(default=0)\n",
    "    class_name: str = field(default=\"\")\n",
    "    centroid: tuple = field(init=False)\n",
    "    def __post_init__(self):\n",
    "        self.centroid = ((self.x1 + self.x2) // 2, (self.y1 + self.y2) // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Edge:\n",
    "    weight: Union[float, int] = field(default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spatial_graph(img, bbox, identities=None, categories=None, confidences = None, names=None, colors = None):\n",
    "    \"\"\"\n",
    "    Construct a spatial graph from the bounding boxes, identities, categories, confidences, names and colors\n",
    "    \"\"\"\n",
    "    graph = nx.Graph()\n",
    "    for i, box in enumerate(bbox):\n",
    "        x1, y1, x2, y2 = [int(i) for i in box]\n",
    "\n",
    "        cat = int(categories[i]) if categories is not None else 0\n",
    "        id = int(identities[i]) if identities is not None else 0\n",
    "        conf = confidences[i] if confidences is not None else 0\n",
    "        class_name = names[cat]\n",
    "        graph.add_node(Node(id, x1, y1, x2, y2, conf, cat, class_name))\n",
    "\n",
    "    for node1 in graph.nodes:\n",
    "        for node2 in graph.nodes:\n",
    "            if node1.id == node2.id: continue\n",
    "            graph.add_edge(node1, node2, weight=distance.euclidean(node1.centroid, node2.centroid))\n",
    "\n",
    "    return img, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[       1647,         121,        1716,         284],\n",
       "       [       1606,         609,        1716,         863],\n",
       "       [        249,         787,         374,        1080],\n",
       "       [        801,         245,         857,         422],\n",
       "       [       1452,          35,        1535,         185],\n",
       "       [       1575,         913,        1715,        1079],\n",
       "       [        713,         229,         783,         409],\n",
       "       [        871,         391,         985,         613],\n",
       "       [       1347,          70,        1395,         151],\n",
       "       [        879,          77,         943,         232],\n",
       "       [       1797,         180,        1864,         367],\n",
       "       [        886,         482,        1022,         643],\n",
       "       [        294,         298,         364,         481],\n",
       "       [        615,          78,         690,         193],\n",
       "       [        616,        1007,         752,        1080],\n",
       "       [       1509,          90,        1553,         192],\n",
       "       [       1646,         686,        1712,         791],\n",
       "       [       1347,          16,        1402,         129],\n",
       "       [       1154,           0,        1197,          75],\n",
       "       [         11,         277,          90,         435],\n",
       "       [        985,           0,        1032,         127],\n",
       "       [       1324,           0,        1358,          47],\n",
       "       [        247,         951,         284,        1023],\n",
       "       [        284,         398,         315,         456],\n",
       "       [        593,         244,         802,         417],\n",
       "       [       1837,         262,        1883,         344],\n",
       "       [       1806,         208,        1857,         292]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "bbox = data[:, :4]\n",
    "identities = data[:, 5]\n",
    "categories = data[:, 4]\n",
    "confidences = data[:, 4]\n",
    "names = [\"person\", \"car\"]\n",
    "colors = [[random.randint(0, 255) for _ in range(3)] for _ in range(len(names))]\n",
    "img = np.zeros((1080, 1920, 3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, graph = generate_spatial_graph(_, bbox, identities, categories, confidences, names, colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e1432e545b0c1cd60505bff387fd0ff464689d608b7f151659873143ae0fbed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
