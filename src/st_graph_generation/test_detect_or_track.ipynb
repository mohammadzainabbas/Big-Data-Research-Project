{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "import cv2\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from numpy import random\n",
    "from typing import List, Tuple, Dict, Any, Union\n",
    "from stg_utils import *\n",
    "\n",
    "from sys import path\n",
    "path.append(\"/Users/mohammadzainabbas/Masters/CS/Big-Data-Research-Project/src/object_detection/yolov7_with_object_tracking\")\n",
    "\n",
    "from models.experimental import attempt_load\n",
    "from utils.datasets import LoadStreams, LoadImages\n",
    "from utils.general import check_img_size, check_requirements, \\\n",
    "                check_imshow, non_max_suppression, apply_classifier, \\\n",
    "                scale_coords, xyxy2xywh, strip_optimizer, set_logging, \\\n",
    "                increment_path\n",
    "from utils.plots import plot_one_box\n",
    "from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n",
    "\n",
    "from sort import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Function to Draw Bounding boxes\"\"\"\n",
    "def draw_boxes(img, bbox, identities=None, categories=None, confidences = None, names=None, colors = None):\n",
    "    for i, box in enumerate(bbox):\n",
    "        x1, y1, x2, y2 = [int(i) for i in box]\n",
    "        tl = opt.thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "\n",
    "        cat = int(categories[i]) if categories is not None else 0\n",
    "        id = int(identities[i]) if identities is not None else 0\n",
    "        # conf = confidences[i] if confidences is not None else 0\n",
    "\n",
    "        color = colors[cat]\n",
    "        \n",
    "        if not opt.nobbox:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), color, tl)\n",
    "\n",
    "        if not opt.nolabel:\n",
    "            label = str(id) + \":\"+ names[cat] if identities is not None else  f'{names[cat]} {confidences[i]:.2f}'\n",
    "            tf = max(tl - 1, 1)  # font thickness\n",
    "            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "            c2 = x1 + t_size[0], y1 - t_size[1] - 3\n",
    "            cv2.rectangle(img, (x1, y1), c2, color, -1, cv2.LINE_AA)  # filled\n",
    "            cv2.putText(img, label, (x1, y1 - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(opt, save_img=False):\n",
    "    source, weights, view_img, save_txt, imgsz, trace = opt.source, opt.weights, opt.view_img, opt.save_txt, opt.img_size, not opt.no_trace\n",
    "    save_img = not opt.nosave and not source.endswith('.txt')  # save inference images\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n",
    "        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    save_dir = Path(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))  # increment run\n",
    "    if not opt.nosave:  \n",
    "        (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Initialize\n",
    "    set_logging()\n",
    "    device = select_device(opt.device)\n",
    "    half = device.type != 'cpu'  # half precision only supported on CUDA\n",
    "\n",
    "    # Load model\n",
    "    model = attempt_load(weights, map_location=device)  # load FP32 model\n",
    "    stride = int(model.stride.max())  # model stride\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n",
    "\n",
    "    if trace:\n",
    "        model = TracedModel(model, device, opt.img_size)\n",
    "\n",
    "    if half:\n",
    "        model.half()  # to FP16\n",
    "\n",
    "    # Second-stage classifier\n",
    "    classify = False\n",
    "    if classify:\n",
    "        modelc = load_classifier(name='resnet101', n=2)  # initialize\n",
    "        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n",
    "\n",
    "    # Set Dataloader\n",
    "    vid_path, vid_writer = None, None\n",
    "    if webcam:\n",
    "        view_img = check_imshow()\n",
    "        cudnn.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n",
    "\n",
    "    # Get names and colors\n",
    "    names = model.module.names if hasattr(model, 'module') else model.names\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n",
    "\n",
    "    # Run inference\n",
    "    if device.type != 'cpu':\n",
    "        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n",
    "    old_img_w = old_img_h = imgsz\n",
    "    old_img_b = 1\n",
    "\n",
    "    t0 = time.time()\n",
    "    ###################################\n",
    "    startTime = 0\n",
    "    ###################################\n",
    "    for path, img, im0s, vid_cap in dataset:\n",
    "        img = torch.from_numpy(img).to(device)\n",
    "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
    "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if img.ndimension() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "\n",
    "        # Warmup\n",
    "        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n",
    "            old_img_b = img.shape[0]\n",
    "            old_img_h = img.shape[2]\n",
    "            old_img_w = img.shape[3]\n",
    "            for i in range(3):\n",
    "                model(img, augment=opt.augment)[0]\n",
    "\n",
    "        # Inference\n",
    "        t1 = time_synchronized()\n",
    "        pred = model(img, augment=opt.augment)[0]\n",
    "        t2 = time_synchronized()\n",
    "\n",
    "        # Apply NMS\n",
    "        pred = non_max_suppression(pred, opt.conf_thres, opt.iou_thres, classes=opt.classes, agnostic=opt.agnostic_nms)\n",
    "        t3 = time_synchronized()\n",
    "\n",
    "        # Apply Classifier\n",
    "        if classify:\n",
    "            pred = apply_classifier(pred, modelc, img, im0s)\n",
    "\n",
    "        # Process detections\n",
    "        for i, det in enumerate(pred):  # detections per image\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n",
    "            else:\n",
    "                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n",
    "\n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # img.jpg\n",
    "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                dets_to_sort = np.empty((0,6))\n",
    "                # NOTE: We send in detected object class too\n",
    "                for x1,y1,x2,y2,conf,detclass in det.cpu().detach().numpy():\n",
    "                    dets_to_sort = np.vstack((dets_to_sort, \n",
    "                                np.array([x1, y1, x2, y2, conf, detclass])))\n",
    "\n",
    "\n",
    "                if opt.track:\n",
    "  \n",
    "                    tracked_dets = sort_tracker.update(dets_to_sort, opt.unique_track_color)\n",
    "                    tracks =sort_tracker.getTrackers()\n",
    "\n",
    "                    # draw boxes for visualization\n",
    "                    if len(tracked_dets)>0:\n",
    "                        bbox_xyxy = tracked_dets[:,:4]\n",
    "                        identities = tracked_dets[:, 8]\n",
    "                        categories = tracked_dets[:, 4]\n",
    "                        confidences = None\n",
    "\n",
    "                        if opt.show_track:\n",
    "                            #loop over tracks\n",
    "                            for t, track in enumerate(tracks):\n",
    "                  \n",
    "                                track_color = colors[int(track.detclass)] if not opt.unique_track_color else sort_tracker.color_list[t]\n",
    "\n",
    "                                [cv2.line(im0, (int(track.centroidarr[i][0]),\n",
    "                                                int(track.centroidarr[i][1])), \n",
    "                                                (int(track.centroidarr[i+1][0]),\n",
    "                                                int(track.centroidarr[i+1][1])),\n",
    "                                                track_color, thickness=opt.thickness) \n",
    "                                                for i,_ in  enumerate(track.centroidarr) \n",
    "                                                    if i < len(track.centroidarr)-1 ] \n",
    "                else:\n",
    "                    bbox_xyxy = dets_to_sort[:,:4]\n",
    "                    identities = None\n",
    "                    categories = dets_to_sort[:, 5]\n",
    "                    confidences = dets_to_sort[:, 4]\n",
    "                \n",
    "                im0 = draw_boxes(im0, bbox_xyxy, identities, categories, confidences, names, colors)\n",
    "\n",
    "                \n",
    "                    \n",
    "                \n",
    "                \n",
    "            # Print time (inference + NMS)\n",
    "            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n",
    "\n",
    "            # Stream results\n",
    "            ######################################################\n",
    "            if dataset.mode != 'image' and opt.show_fps:\n",
    "                currentTime = time.time()\n",
    "\n",
    "                fps = 1/(currentTime - startTime)\n",
    "                startTime = currentTime\n",
    "                cv2.putText(im0, \"FPS: \" + str(int(fps)), (20, 70), cv2.FONT_HERSHEY_PLAIN, 2, (0,255,0),2)\n",
    "\n",
    "            #######################################################\n",
    "            if view_img:\n",
    "                cv2.imshow(str(p), im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                    print(f\" The image with the result is saved in: {save_path}\")\n",
    "                else:  # 'video' or 'stream'\n",
    "                    if vid_path != save_path:  # new video\n",
    "                        vid_path = save_path\n",
    "                        if isinstance(vid_writer, cv2.VideoWriter):\n",
    "                            vid_writer.release()  # release previous video writer\n",
    "                        if vid_cap:  # video\n",
    "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        else:  # stream\n",
    "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                            save_path += '.mp4'\n",
    "                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                    vid_writer.write(im0)\n",
    "\n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        #print(f\"Results saved to {save_dir}{s}\")\n",
    "\n",
    "    print(f'Done. ({time.time() - t0:.3f}s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = dict_with_attributes(dict(weights='/Users/mohammadzainabbas/Masters/CS/Big-Data-Research-Project/src/object_detection/yolov7_with_object_tracking/yolov7.pt', source='data/street.mp4', img_size=640, conf_thres=0.25, iou_thres=0.45, device='', view_img=True, save_txt=False, save_conf=False, nosave=False, classes=None, agnostic_nms=False, augment=False, update=False, project='detects', name='test', exist_ok=False, no_trace=True, track=True, show_track=True, show_fps=True, thickness=2, seed=2, nobbox=False, nolabel=False, unique_track_color=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mohammadzainabbas/Masters/CS/Big-Data-Research-Project/src/object_detection/yolov7_with_object_tracking/yolov7.pt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('yolov7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e1432e545b0c1cd60505bff387fd0ff464689d608b7f151659873143ae0fbed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
